---
title: "D√©tection automatique d'objets avec YOLO et Panoramax !"
authors:
    - Adrien PAVIE
categories:
    - article
comments: true
date: 2024-03-10
description: Apprenez √† utiliser YOLO pour d√©tecter vos propres objets dans des photos Panoramax pour mieux r√©pondre √† vos besoins SIG !
icon: robot
image: https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/labelstudio_annotation.jpg
license: cc4_by-sa
robots: index, follow
tags:
    - Panoramax
    - OpenStreetMap
    - Python
    - vues immersives
    - IA
---

# üñºÔ∏èü§ñ Tutoriel : d√©tection automatique d'objets avec YOLO et Panoramax !

![Logos des logiciels](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/logos.png)

Bienvenue sur ce tutoriel ! Ce tutoriel vous guidera dans la cr√©ation d'un mod√®le sur-mesure de d√©tection d'objets √† l'aide des photos de rues provenant de Panoramax, et en utilisant YOLOv8 et Label Studio. Nous d√©couvrirons ensemble comment :

- Trouver des localisations d'objets √† d√©tecter via __OpenStreetMap__
- R√©cup√©rer des images exemples depuis __Panoramax__
- Annoter les images en utilisant __Label Studio__
- Entra√Æner un mod√®le de d√©tection avec __YOLOv8__
- D√©tecter des objets dans les images Panoramax

Nous explorerons √©galement le processus de r√©-entra√Ænement bas√© sur les faux positifs afin d'affiner le mod√®le. Le but est de vous rendre autonome sur la d√©tection d'objets, de A √† Z.

Les fichiers d'exemple ou de configuration utilis√©s dans cet article sont disponible sur [le d√©p√¥t Git o√π le tutoriel a √©t√© initialement publi√©](https://github.com/panoramax-project/DetectionTutorial).

## üåê Vue d'ensemble

[YOLOv8](https://docs.ultralytics.com/), ou _You Only Look Once (version 8)_, est un algorithme de d√©tection d'objets puissant, massivement utilis√© dans le domaine de la _vision par ordinateur_ (_computer vision_). Il offre une pr√©cision et une performance accrues dans les t√¢ches de d√©tection d'objets en temps r√©el. YOLOv8 est particuli√®rement appr√©ci√© pour sa capacit√© √† d√©tecter et √† classer rapidement des objets dans des images ou vid√©os. YOLOv8 utilise un unique r√©seau neuronal pour pr√©dire plusieurs classes d'objets et leur emplacement dans l'image.

L'annotation des images sera une √©tape cl√© pour bien d√©tecter les objets. Le but est d'apprendre √† l'algorithme √† quoi ressemblent les objets recherch√©s. Nous devons expliquer √† l'aide de nombreux exemples, que tel objet est par exemple une voiture, et qu'elle est √† cet endroit de l'image. Pour ce faire, nous allons dessiner sur l'image des rectangles pour d√©limiter les objets, et nous attribuerons √† chacun d'entre eux une √©tiquette (ou classe) pour distinguer les diff√©rents objets.

Mais pour pouvoir annoter les images, encore faut-il avoir un stock de photos avec des exemples d'objets √† trouver. Nous utiliserons ici [OpenStreetMap](https://www.openstreetmap.org/) et [Panoramax](https://panoramax.fr/) pour trouver des photos pertinentes. OpenStreetMap (OSM) est un projet de cartographie collaboratif mondial, souvent surnomm√© le _Wikipedia des cartes_. Il s'agit d'une vaste base de donn√©es g√©ographiques o√π des contributeurs du monde entier peuvent participer activement au recensement des nombreuses donn√©es cartographiques. OSM permet √† chacun de contribuer facilement, ce qui en fait une ressource pr√©cieuse et particuli√®rement d√©taill√©e. Nous allons donc commencer par extraire la position des objets que nous recherchons dans OpenStreetMap, puis demander √† Panoramax de nous fournir des photos montrant les objets en question.

Avec ce stock d'images exemples, nous allons pouvoir commencer l'annotation. [Label Studio](https://labelstud.io/) est un logiciel libre con√ßu pour les t√¢ches d'√©tiquetage et d'annotation de donn√©es. Il s'agit d'un outil complet permettant d'√©tiqueter efficacement divers jeux de donn√©es (images, textes, fichiers audio) pour les mod√®les d'apprentissage automatique. Les donn√©es annot√©es seront ensuite export√©es pour entra√Æner un mod√®le YOLO.

Avec le mod√®le entra√Æn√© par YOLO, nous pourrons effectuer des d√©tections d'objets √† grande √©chelle, en utilisant les photos de Panoramax. Nous nous appuierons sur un script Python pour parcourir le catalogue, faire travailler le mod√®le YOLO, puis exporter les images int√©ressantes et un fichier GeoJSON listant les positions des images montrant les objets d√©tect√©s.

Maintenant que vous avez une bonne vue d'ensemble, mettons les mains dans le cambouis !

## üì∑üó∫Ô∏è Trouver des images avec Panoramax & OpenStreetMap

### Localiser les objets recherch√©s avec OpenStreetMap

La premi√®re √©tape est de trouver des images avec les objets √† rechercher, afin de pouvoir entra√Æner notre mod√®le. Dans ce tutoriel, nous allons chercher des __bornes incendies__ (_fire hydrants_) üî•üíß. Pour r√©cup√©rer des localisations exemples de ces objets, nous nous appuierons sur les donn√©es d'OpenStreetMap. En particulier, nous utiliserons ici un outil nomm√© [Overpass Turbo](https://overpass-turbo.eu/), qui est un explorateur th√©matique de donn√©es OSM, facile √† utiliser.

Le moyen le plus rapide d'obtenir les donn√©es souhait√©es est d'utiliser le bouton __Assistant__. Dans la pop-up, tapez en anglais le type d'objet que vous recherchez, par exemple ici :

> "fire hydrant" in Lyon

![L'assistant d'Overpass Turbo](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/overpass_assistant.png)

Puis, cliquez sur _Construire et ex√©cuter_. Les donn√©es vont appra√Ætre sur la carte :

![Bornes incendies d'OSM sur Lyon dans Overpass Turbo](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/overpass_data.png)

Les donn√©es d'OpenStreetMap peuvent ensuite √™tre export√©es via le bouton __Exporter__. Enregistrez-les au format __GeoJSON__. Si vous avez le moindre souci pendant cette √©tape, un fichier exemple [`osm_hydrants_lyon.geojson`](https://github.com/panoramax-project/DetectionTutorial/blob/main/osm_hydrants_lyon.geojson) est √©galement fourni avec le tutoriel.

### T√©l√©charger les photos √† proximit√© avec Panoramax

[L'API de Panoramax](https://panoramax.ign.fr/api/docs/swagger#/Pictures/get_api_search) propose une _route_ pour trouver les photos pointant sur une localisation pr√©cise. Vous pouvez l'appeler avec une requ√™te _HTTP GET_:

```
https://panoramax.ign.fr/api/search?place_distance=2-10&place_position=4.8444928,45.7719378
```

Vous obtiendrez ainsi la liste des images montrant la position en question (longitude, latitude), au format GeoJSON. La premi√®re image list√©e est la plus proche.

Comme nous aurons besoin de nombreuses images (des centaines), nous pouvons automatiser ce processus √† l'aide d'un script Python. C'est ce que fait le script [`find_pics.py`](https://github.com/panoramax-project/DetectionTutorial/blob/main/find_pics.py).

Avant √ßa, cr√©ons un environnement de travail Python :

```bash
# R√©cup√©ration des fichiers du tutoriel
git clone https://github.com/panoramax-project/DetectionTutorial.git
cd DetectionTutorial/

# Cr√©ation de l'environnement virtuel
python -m venv env
source ./env/bin/activate

# Installation des d√©pendances
pip install -r requirements.txt
```

Vous pouvez jeter un coup d'oeil au [script](https://github.com/panoramax-project/DetectionTutorial/blob/main/find_pics.py), en particulier si vous voulez changer certains param√®tres d'entr√©e :

```python
# L'API Panoramax √† utiliser
PANORAMAX_API="https://api.panoramax.xyz/api"
# Fichier GeoJSON de d√©part
OSM_FEATURES="./osm_hydrants_lyon.geojson"
# Nombre de photos √† r√©cup√©rer
WANTED_PICTURES=100
# Dossier de sauvegarde des photos
PICTURES_OUTPUT_FOLDER="./training_pictures"
```

Une fois pr√™t, vous pouvez lancer le script avec cette commande :

```bash
python ./find_pics.py
```

Il va interroger Panoramax pour voir si une photo existe pour chaque borne incendie, puis t√©l√©chargez la photo dans une taille standard.

![Photos t√©l√©charg√©es depuis Panoramax](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/python_downloaded_pics.png)

Si vous consultez les images, la majorit√© d'entre elles doivent laisser appara√Ætre une borne incendie. Avec tout √ßa, vous √™tes pr√™ts pour l'annotation !

## üè∑Ô∏è Annotation des photos avec Label Studio

### Configuration initiale

[Label Studio](https://labelstud.io/) nous permet d'annoter facilement un lot d'images √† l'aide d'une interface web simple d'utilisation. Il est normalement d√©j√† disponible dans votre environnement virtuel Python, ou vous pouvez sinon l'installer [en vous appuyant sur la documentation officielle](https://labelstud.io/guide/start).

Pour d√©marrer Label Studio, lancez la commande :

```bash
label-studio
```

Label Studio est d√©sormais disponible √† l'adresse [`localhost:8080`](http://localhost:8080/).

Au premier d√©marrage, l'outil vous demandera de vous enregistrer avec un email et mot de passe. Une fois enregistr√©, la page d'accueil ressemble √† √ßa:

![Accueil de Label Studio](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/labelstudio_home.png)

On va cr√©er un nouveau projet, que l'on appellera par exemple _Bornes incendies_.

![Configuration d'un projet Label Studio](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/labelstudio_setup1.png)

Allez ensuite dans l'onglet _Labelling setup_, on choisira ici _Computer vision_ dans le menu lat√©ral, puis _Object detection with bounding boxes_. √Ä noter que Label Studio propose de tr√®s nombreux mod√®les pour plein de cas d'usages.

![Configuration de l'annotation](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/labelstudio_setup2.png)

Ensuite, nous devons lister nos _classes_ (_labels_), les cat√©gories que nous utiliserons pour √©tiqueter les images. Pour commencer, cr√©ez une √©tiquette appel√©e `pillar` (une borne d'incendie classique, la _chose rouge_ que l'on voit dans les rues).

![D√©finition d'√©tiquette dans Label Studio](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/labelstudio_setup3.png)

Enfin, sauvegardez les param√®tres. Maintenant, chargeons les photos !

### Import des images

Sur la page principale du projet, vous pouvez cliquer sur le bouton _Import_ pour commencer l'import des photos exemples.

![Page d'import de Label Studio](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/labelstudio_import.png)

S√©lectionnez toutes les images t√©l√©charg√©es depuis Panoramax (dans le dossier `training_pictures`) et cliquez sur _Import_. Cela peut prendre quelques instants. Elles doivent maintenant appara√Ætre sur la page principale du projet.

![T√¢ches de Label Studio](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/labelstudio_tasks.png)

### Annotation des images

L'√©tape suivante consiste √† annoter nos images. Commencez par cliquer sur une image dans la liste, ce qui affichera la page d'annotation pour cette image.

Vous pouvez ajouter une √©tiquette sur l'image en cliquant sur le bouton _pillar_, en dessous de l'image. Ensuite, dessinez un rectangle sur l'image pour d√©limiter la borne d'incendie. Essayez de rendre le rectangle aussi ajust√© que possible.

![Outil d'annotation d'image](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/labelstudio_annotation.jpg)

R√©p√©tez ce processus pour chaque objet dans l'image. Une fois que tout est √©tiquet√© dans cette premi√®re image, cliquez sur le bouton _Submit_ en bas √† droite.

Ensuite, r√©p√©tez le processus pour chaque image que vous avez import√©e. Oui, je sais, c'est _pas franchement hyper stimulant_ ‚è≤Ô∏èü•±, mais cette √©tape est essentielle pour permettre un bon entra√Ænement du mod√®le. Comme tout bon prof des √©coles, on passe beaucoup de temps √† pr√©parer un bon cours pour ses √©l√®ves.

### Export du jeu de donn√©es

Une fois que vous avez termin√© l'annotation des images, vous pouvez exporter l'ensemble en utilisant le bouton _Export_ sur la page du projet. Choisissez le format d'export _YOLO_. Cela g√©n√©rera une archive ZIP dont nous aurons besoin pour l'entra√Ænement du mod√®le.

![Param√®tres d'export dans Label Studio](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/labelstudio_export.png)

Avant de commencer l'entra√Ænement, nous devons diviser le jeu de donn√©es t√©l√©charg√© en deux sous-ensembles d'images:

- Les __images d'entra√Ænement__, qui seront utilis√©es pour apprendre au mod√®le ce qu'il doit d√©tecter
- Les __images de validation__, qui seront utilis√©es apr√®s l'apprentissage pour v√©rifier la pr√©cision du mod√®le

Pour avoir un entra√Ænement optimal, il faut avoir environ 80% d'images d'entra√Ænement et 20% d'images de validation. Pour diviser notre jeu de donn√©es, vous pouvez faire ce qui suit :

- Extrayez une premi√®re fois le fichier ZIP export√© et nommez-le `hydrants_data_v1`. Ce sera notre jeu de donn√©es __d'entra√Ænement__.
    - Allez dans le r√©pertoire extrait.
    - Supprimez 20% des images du dossier `pictures` (assurez-vous qu'elles sont tri√©es par nom de fichier).
    - Supprimez le m√™me nombre de fichiers texte dans le dossier `labels` (m√™mes noms que les images supprim√©es).
- Extrayez une deuxi√®me fois le fichier ZIP export√© et nommez-le `hydrants_data_validation`. Ce sera notre jeu de donn√©es de __validation__.
    - Allez dans le r√©pertoire extrait.
    - Supprimez 80% des images du dossier `pictures` (assurez-vous qu'elles sont tri√©es par nom de fichier).
    - Supprimez le m√™me nombre de fichiers texte dans le dossier `labels` (m√™mes noms que les images supprim√©es).

Notre jeu de donn√©es initial est pr√™t. Il est temps pour nous d'entra√Æner le mod√®le YOLO.

## üèÉ‚Äç‚ôÄÔ∏è Entra√Ænement du mod√®le avec YOLO

### Configuration

Avant de commencer l'installation, notez que les outils dont nous avons besoin utilisent pas mal d'espace disque (environ 6 Go) et offriront de meilleures performances si vous avez une _carte graphique pas trop mauvaise_. Cependant, vous pouvez aussi utiliser un processeur classique (CPU), mais l'entra√Ænement du mod√®le prendra beaucoup plus de temps.

YOLO a besoin que PyTorch soit install√© pour fonctionner correctement. [Consultez la documentation d'installation](https://pytorch.org/get-started/locally/) car celle-ci d√©pend fortement de votre environnement et de votre mat√©riel. La commande d'installation peut ressembler √† ceci :

```bash
pip install torch torchvision
```

Une fois que PyTorch est install√©, vous pouvez [installer YOLOv8](https://docs.ultralytics.com/quickstart/#install-ultralytics) avec cette commande (ou il peut d√©j√† √™tre disponible dans votre environnement Python si vous avez utilis√© `requirements.txt`):

```bash
pip install ultralytics
```

### Entra√Ænement de notre premier mod√®le üë∂

√áa y est, nous sommes fins pr√™ts √† entra√Æner notre premier mod√®le de d√©tection d'objets ! On commence par cr√©er un petit fichier de configuration pour YOLO. Il doit √™tre nomm√© `data.yaml` et avoir le contenu suivant :

```yaml
train: /chemin/vers/hydrants_data_v1/images
val: /chemin/vers/hydrants_data_validation/images
nc: 1
names: ['pillar']
```

Modifiez les param√®tres pour qu'ils correspondent √† votre environnement :

- `train` : pour pointer sur le dossier `images` √† l'int√©rieur de votre r√©pertoire `hydrants_data_v1`
- `val` : pour pointer sur le dossier `images` √† l'int√©rieur de votre r√©pertoire `hydrants_data_validation`
- `names` : si vous avez utilis√© un nom d'√©tiquette diff√©rent de `pillar`

Maintenant, nous sommes pr√™ts √† lancer l'entra√Ænement ! Notez que la carte graphique va chauffer un peu üå°Ô∏è Lancez la commande suivante :

```bash
yolo detect train \
 data=./hydrants_data_v1/data.yaml \
 model=yolov8n.pt \
 project=hydrants_model_v1 \
 epochs=100 imgsz=2048 batch=-1
```

Nous utilisons ici le mod√®le de base `yolov8n.pt` ([voir tous les mod√®les disponibles dans la documentation](https://docs.ultralytics.com/models/yolov8/#supported-tasks-and-modes)), bien s√ªr cela peut √™tre modifi√© pour am√©liorer la pr√©cision ou la performance du mod√®le produit.

Notez √©galement que le param√®tre `imgsz=2048` doit correspondre √† la largeur r√©elle des images t√©l√©charg√©es. Dans le script `find_pics.py` que nous avons utilis√©, toutes les images ont √©t√© t√©l√©charg√©es avec une largeur de 2048 pixels. N'oubliez pas de changer la valeur ici si vous avez une taille d'image diff√©rente.

![Entra√Ænement YOLO et surconsommation du GPU](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/yolo_training.png)

Apr√®s quelques minutes, un nouveau dossier nomm√© `hydrants_model_v1` doit √™tre disponible. Dans le sous-dossier `train`, vous trouverez diff√©rents fichiers permettant de comprendre les r√©sultats de l'entra√Ænement du mod√®le.

Pour commencer, nous allons uniquement utiliser le fichier `weights/best.pt`. C'est le fichier de _poids_, qui contient les param√®tres et poids retenus par le mod√®le, lui permettant de faire des pr√©dictions/d√©tections pr√©cises. En r√©sum√©, c'est √ßa __le mod√®le entra√Æn√©__ ! On va maintenant le mettre √† profit.

### Ex√©cution manuelle du mod√®le

Pour v√©rifier si tout s'est bien d√©roul√©, vous pouvez essayer votre mod√®le en ex√©cutant manuellement la commande suivante sur une image exemple :

```bash
yolo predict \
    project=hydrants_model_v1 \
    model=./hydrants_model_v1/train/weights/best.pt \
    source=https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/pic_with_hydrant.jpg \
    imgsz=2048 save_txt=True
```

Bravo, vous avez d√©tect√© automatiquement votre premier objet ! üéÜ Les r√©sultats seront disponibles dans le dossier `hydrants_model_v1/predict`.

![Image avec borne d'incendie d√©tect√©e](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/yolo_predict.jpg)

Notez que le score apparaissant sur l'image est √©valu√© entre 0 et 1. C'est un score de confiance, indiquant √† quel point le mod√®le est s√ªr de sa d√©tection. Plus le score est √©lev√©, mieux c'est.

Maintenant que notre premier mod√®le fonctionne, automatisons la d√©tection d'objets √† plus grande √©chelle.

## üîç D√©tection d'objets sur des images Panoramax

Nous voulons lancer ce mod√®le sur toutes les images provenant de Panoramax, sur une certaine zone g√©ographique. On obtiendra ainsi une liste des coordonn√©es o√π les bornes d'incendie sont visibles sur les photos, des donn√©es bien utiles !

On va utiliser le script Python nomm√© [`predict_pano.py`](https://github.com/panoramax-project/DetectionTutorial/blob/main/predict_pano.py). Vous pouvez y jeter un ≈ìil, surtout si vous souhaitez modifier les param√®tres :

```python
# L'API Panoramax √† utiliser
PANORAMAX_API="https://api.panoramax.xyz/api"
# La zone de recherche (min X, min Y, max X, max Y)
SEARCH_BBOX=[2.25256,48.96895,2.26447,48.97247]
# Chemin vers votre fichier mod√®le ".pt" entra√Æn√©
MODEL_PATH="hydrants_model_v1/train/weights/best.pt"
# Fichier GeoJSON de sortie
OUTPUT_GEOJSON="./detected_features.geojson"
# Dossier de sortie pour les images o√π des bornes ont √©t√© rep√©r√©es
OUTPUT_PICTURES="./detected_features_pictures"
# Nombre d'images √† analyser en une fois
PICS_CHUNK_SIZE=10
```

Le script complet r√©alise les op√©rations suivantes :

- Lire votre mod√®le entra√Æn√©
- Trouver les images disponibles sur Panoramax dans la zone de recherche
- T√©l√©charger les fichiers JPEG des images 10 par 10 (ici nomm√© "chunks")
- Ex√©cuter la pr√©diction sur ce groupe d'images pour trouver les bornes d'incendie
- Enregistrer la position et les images lorsque une borne d'incendie est d√©tect√©e

Vous pouvez le lancer avec cette commande :

```bash
python ./predict_pano.py
```

Apr√®s un certain temps (pr√©voyez quelques minutes ou plus selon la taille de la zone souhait√©e), de nombreuses images seront disponibles dans le dossier `detected_features_pictures`, ainsi qu'un fichier `detected_features.geojson` montrant la position des bornes d√©tect√©es.

Si vous regardez d'un peu plus pr√®s les r√©sultats, vous pouvez vous attendre √† quelques surprises üò≤

![Mauvaise d√©tection d'un feu arri√®re de voiture](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/detections_carlight.jpg)

![Mauvaise d√©tection d'un c√¥ne de signalisation](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/detections_cone.jpg)

Ce sont des _faux positifs_ ‚ùå, des d√©tections qui ne correspondent pas √† ce que vous recherchez. Vous pouvez vous attendre √† en avoir beaucoup dans votre premi√®re version du mod√®le. _Pas de soucis_, nous les traiterons plus tard üòâ

On peut √©galement faire face √† des _faux n√©gatifs_ üëª, des images qui contiennent une borne d'incendie mais qui sont pass√©es / ignor√©es par le mod√®le. Ceux-ci sont plus difficiles √† trouver car aucun fichier n'est t√©l√©charg√©. Si vous souhaitez les identifier, vous pouvez vous appuyer sur l'API Panoramax que nous avons utilis√©e dans la premi√®re partie pour r√©cup√©rer des exemples d'images. Avec un jeu de donn√©es de r√©f√©rence, vous pouvez trouver toutes les images disponibles et v√©rifier si elles ont √©t√© identifi√©es par votre mod√®le.

## üìà Am√©lioration du mod√®le

### √âlargir le jeu de donn√©es d'entra√Ænement

Afin de limiter les faux positifs et les faux n√©gatifs, nous pouvons √©largir notre lot d'images annot√©es. Cela peut √™tre fait en utilisant les r√©sultats de la premi√®re ex√©cution des d√©tections (dans le dossier `detected_features_pictures`). Regardez les images et mettez de c√¥t√© :

- Les images ayant un objet d√©tect√© √† tort comme une borne d'incendie (c√¥nes de signalisation, feux arri√®re de voiture, panneaux de signalisation...)
- Les images ayant une borne d'incendie d√©tect√©e avec un score de confiance faible (moins de 0,5)

Afin de permettre au mod√®le de mieux distinguer les bornes d'incendie des autres objets, nous allons cr√©er de nouvelles √©tiquettes/classes dans Label Studio. Ici, on va cr√©er les nouvelles √©tiquettes suivantes :

- C√¥nes de signalisation
- Feux arri√®re de voiture
- Panneaux de signalisation rouges
- V√™tements rouges

Retournez dans Label Studio et ajoutez-les dans les param√®tres de votre projet.

![Nouvelles √©tiquettes dans les param√®tres du projet Label Studio](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/labelstudio_labels2.png)

Ensuite, allez sur la page d'import et importez les images avec de faux n√©gatifs ou des d√©tections √† faible confiance.

![Importez davantage d'images dans Label Studio](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/labelstudio_import2.png)

Une fois les images import√©es, on retourne dans l'outil d'annotation des images (oui je sais, _trop chiant_ üôÉ). Vous allez en particulier :

- Ajouter les nouvelles √©tiquettes dans __les images d√©j√† annot√©es__
- Ajouter toutes les √©tiquettes dans les images fra√Æchement import√©es

![Nouvelles √©tiquettes dans une image](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/labelstudio_annotation2.jpg)

Assurez-vous que chaque classe ait au moins une centaine d'annotations sur l'ensemble des images. Si une classe est moins repr√©sent√©e que les autres, elle sera moins utile pour identifier les faux positifs.

Une fois que vous avez termin√©, refaites l'export comme pour la premi√®re version du mod√®le. Exportez au format YOLO et enregistrez le fichier ZIP g√©n√©r√©.

### R√©-entra√Æner le mod√®le

On doit d√©sormais r√©-entra√Æner le mod√®le avec les nouvelles images annot√©es. Comme dans la version pr√©c√©dente, nous devons diviser nos images en deux lots (entra√Ænement et validation), toujours avec un ratio 80% / 20%. Cr√©ez un dossier `hydrants_data_v2` pour les images d'entra√Ænement, et un dossier `hydrants_data_validation` pour les images de validation.

Et comme dans la premi√®re pr√©paration du mod√®le, nous aurons besoin d'un fichier `data.yaml` associ√© √† cet ensemble de donn√©es export√©. Cr√©ez-le dans le dossier `hydrants_data_v2`, mais cette fois avec un contenu un peu diff√©rent :

```yaml
train: /chemin/vers/hydrants_data_v2/images
val: /chemin/vers/hydrants_data_validation/images
nc: 5
names: ['cone', 'pillar', 'rearlight', 'redclothes', 'redsign']
```

- `train` et `val` : pointant vers le dossier contenant vos images du deuxi√®me ensemble de donn√©es
- `nc` : nombre de classes
- `names` : la liste des noms de classes, dans le m√™me ordre que dans le fichier `hydrants_data_v2/classes.txt`

Une fois que le fichier de configuration est pr√™t, nous pouvons relancer l'entra√Ænement YOLO :

```bash
yolo detect train \
    data=./hydrants_data_v2/data.yaml \
    model=yolov8n.pt \
    project=hydrants_model_v2 \
    epochs=100 imgsz=2048 batch=-1
```

Apr√®s un certain temps de traitement, un nouveau dossier `hydrants_model_v2` sera disponible. Nous allons examiner de plus pr√®s les statistiques g√©n√©r√©es (dans le sous-dossier `train`). Regardons par exemple la __Matrice de Confusion Normalis√©e__ (`confusion_matrix_normalized.png`). Elle r√©pertorie les √©tiquettes confondues avec une autre classe.

![Matrice de confusion normalis√©e](https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/yolo_confusionmatrix.png)

Cela se lit de la mani√®re suivante :

- L'axe vertical de gauche est la __classe pr√©dite__, ce que le mod√®le pense avoir trouv√© comme objet
- L'axe horizontal du bas est la __classe r√©elle__, ce qui est r√©ellement visible sur l'image (d'apr√®s vos photos de validation)

La chose la plus importante √† lire est ce qui arrive aux bornes incendie du jeu de validation, en particulier celles qui ne sont pas identifi√©es comme bornes. Sur cette matrice exemple, nous voyons que :

- 68% des bornes du jeu de validation sont correctement identifi√©s comme des bornes par le mod√®le (_vrais positifs_)
- 32% d'entre elles ne sont pas d√©tect√©es par le mod√®le (_faux n√©gatifs_)

Ce n'est pas extr√™mement bon, mais ce n'est pas _si mal_ non plus. Une autre m√©trique concerne les _faux positifs_, des √©l√©ments d√©tect√©s comme des piliers l√† o√π ils ne le sont pas. Ici, aucun pilier dans l'ensemble de donn√©es de validation ne ressort en tant que panneau de signalisation rouge, c√¥ne de signalisation, feu arri√®re de voiture... Ce qui est une bonne nouvelle !

[Plus d'infos sur l'interpr√©tation de ces r√©sultats sont disponibles dans la documentation de YOLO](https://docs.ultralytics.com/guides/yolo-performance-metrics/).

Ces donn√©es peuvent vous aider √† am√©liorer votre ensemble de donn√©es d'entra√Ænement en ciblant les classes sur lesquelles vous devriez travailler en premier.

### Pr√©diction manuelle

Vous pouvez r√©-ex√©cuter votre nouveau mod√®le manuellement avec la commande suivante :

```bash
yolo predict \
 project=hydrants_model_v2 \
 model=./hydrants_model_v2/train/weights/best.pt \
 source=https://raw.githubusercontent.com/panoramax-project/DetectionTutorial/main/Images/pic_with_hydrant.jpg \
 classes=1 \
 imgsz=2048 save_txt=True
```

__Notez bien__ le nouveau param√®tre `classes=1`, qui indique que vous souhaitez uniquement d√©tecter des objets correspondant √† l'√©tiquette avec l'ID 1. Cela correspond √† la __deuxi√®me__ entr√©e de la liste des classes du fichier `classes.txt` (les identifiants commencent √† z√©ro). Ici, l'ID 1 correspond donc √† `pillar`, notre √©tiquette de borne d'incendie.

### D√©tection automatique dans les images Panoramax

Vous pouvez √©galement relancer le script `predict_pano.py` pour d√©tecter des objets dans une zone de recherche donn√©e avec les photos Panoramax. __Notez √©galement ici__ que vous devez changer le param√®tre d'ID de classe, de mani√®re similaire √† la d√©tection manuelle :

```python
# ID de classe √† cibler dans les d√©tections
CLASS_ID=1
```

Vous allez ainsi obtenir un nouvel ensemble de bornes incendies d√©tect√©es depuis Panoramax, avec un niveau de qualit√© meilleur.

### Am√©lioration continue du mod√®le

Apr√®s une deuxi√®me ex√©cution, vous pourriez remarquer une am√©lioration des r√©sultats, avec moins de faux positifs ou n√©gatifs. Vous pouvez continuer √† affiner votre mod√®le en r√©it√©rant ces √©tapes :

- Identifier les faux positifs ou n√©gatifs
- Importer de nouvelles images et les annoter dans Label Studio
- √âventuellement cr√©er de nouvelles classes si vous trouvez de nouveaux faux positifs r√©currents (par exemple, des murs de briques confondus avec des bornes d'incendie)
- Entra√Æner √† nouveau le mod√®le

Lorsque vous entra√Ænez √† nouveau votre mod√®le, vous pouvez d√©finir le param√®tre `model` diff√©remment :

- Si vous conservez les m√™mes classes que lors de l'it√©ration pr√©c√©dente, le mod√®le peut √™tre d√©fini comme √©tant votre dernier fichier `best.pt`
- Si vous changez la liste des classes, le mod√®le doit √™tre le mod√®le YOLO initial (ici `yolov8n.pt`)

Lorsque vous avez suffisamment confiance en votre mod√®le, vous pouvez √©galement ajouter un param√®tre `conf=0.5` dans vos pr√©dictions manuelles ou dans le script `predict_pano.py`. Avec ce param√®tre, seules les d√©tections avec un score de confiance sup√©rieur √† la valeur d√©finie seront conserv√©es, √©vitant le _bruit_ dans les r√©sultats.

Un autre param√®tre qui peut aider √† am√©liorer les r√©sultats est `imgsz`. Nous avons vu qu'il devrait correspondre √† la largeur de vos images. Utiliser des valeurs plus basses peut aider √† d√©tecter des objets au premier plan (trop grands pour √™tre reconnus sinon), et utiliser des valeurs plus √©lev√©es peut aider √† d√©tecter des objets √† l'arri√®re-plan (trop petits pour √™tre reconnus sinon).

## üëã Conclusion

Vous avez pu d√©couvrir avec ce tutoriel tout le potentiel de la d√©tection d'objets avec YOLOv8. Panoramax et OpenStreetMap nous ont permis d'obtenir facilement un jeu de donn√©es d'entra√Ænement. Label Studio nous a aid√©s gr√¢ce √† son interface utilisateur simple pour √©tiqueter les images. Tous ces outils offrent un √©cosyst√®me puissant pour d√©tecter √† grande √©chelle les objets de votre choix sur un stock cons√©quent de photos.

Si vous avez des questions ou remarques, l'√©quipe Panoramax est l√† pour vous aider ! Vous pouvez discuter avec nous sur :

- Le [Forum des G√©ocommuns](https://forum.geocommuns.fr/c/panoramax/6)
- Par e-mail √† l'adresse [panoramax@panoramax.fr](mailto:panoramax@panoramax.fr)
- Le [d√©p√¥t de publication initiale de ce tutoriel](https://github.com/panoramax-project/DetectionTutorial), en y cr√©ant un ticket.

----

## Auteur {: data-search-exclude }

--8<-- "content/team/apav.md"

{% include "licenses/cc4_by-sa.md" %}
